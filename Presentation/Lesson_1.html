<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Spartan HPC Lessons</title>

    <meta name="description" content="Slides for the introductory course on the Spartan HPC system.">
    <meta name="author" content="Lev Lafayette"">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>

    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
</head>

<body>

<div class="reveal">

    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">
<!-- to give this presentation list items numbered A, B, C etc.. for use in questions -->
<style type="text/css">.reveal ol {list-style-type: upper-alpha;}</style>
<!-- Slides go here -->
<section data-markdown><script type="text/template">
### Part 0: Welcome! 
* Lev Lafayette has worked as an HPC sysadmin for since 2007, first at the Victorian Partnership for Advanced Computing, now at the University of Melbourne. Has worked in IT since 1999.
* Has taught approximately 175 day-long classes at 17 different research institutions across Australia since 2012.
* Collects degrees for fun.
* Stalk him at: http://levlafayette.com/ or https://www.linkedin.com/in/levlafayette
</script></section>
<section data-markdown><script type="text/template">
### Part 0: Welcome!
* David Perry is an engineer and scientist, and completed his PhD "Temporal Processing in the Deafened Auditory Cortex" in 2003. He's since worked in bionics, climate change, renewable energy, agriculture and the internet of things.
* Stalk him at Twitter @dwjperry
</script></section>
<section data-markdown><script type="text/template">
### Part 0: Goals for today
* Part 1: Physical Architecture and Parallel Limits
* Part 2: Job Submissions and Parallel Extensions
* Part 3: Programming in Parallel with OpenMP
* Part 4: Programming in Parallel with OpenMPI
</script></section>
<section data-markdown><script type="text/template">
### Part 0: Slide Respository
* A copy of the slides and same code is available at: https://github.com/UoM-ResPlat-DevOps/SpartanParallel
</script></section>
<section data-markdown><script type="text/template">
### Part 1: Flynn's Taxonomy
* The type parallelisation can be determined by Flynn's taxonomy of computer Systems (1966), where each process is considered as the execution of a pool of instructions (instruction stream) on a pool of data (data stream), and with these streams are single or multiple. 
* Four basic possibilities: Single Instruction Stream, Single Data Stream (SISD), Single Instruction Stream, Multiple Data Streams (SIMD), Multiple Instruction Streams, Single Data Stream (MISD), Multiple Instruction Streams, Multiple Data Streams (MIMD)
</script></section>
<section data-markdown><script type="text/template">
### Part 1: Processors and Cores
* A processor is a physical device that accepts data as input and provides results as output. A uniprocessor system has one such general purpose device. 
* A unicore processor carries out the usual functions of a CPU, according to the instruction set. A multicore processor has independent central processing units ('cores') integrated a single integrated circuit die or a single chip package.
</script></section>
<section data-markdown><script type="text/template">
### Part I: Threads
* A process provides the resources to execute an instance of a program (such as address space, the code, handles to system objects, a process identifier etc).  An execution thread is the smallest processing unit in an operating system, contained inside a process. 
</script></section>
<section data-markdown><script type="text/template">
### Part 1: Multicore Drivers
<img src="https://raw.githubusercontent.com/UoM-ResPlat-DevOps/SpartanParallel/master/Images/intelcpu.png" />
</script></section>
<section data-markdown><script type="text/template">
### Part 1: Multicore Drivers
* Datasets are becoming larger than computers are improving.
* Effective clock speeds have flattened due to heat and power.
* Increasing gap between memory and processing speeds. 
* Symmetric multiprocessing is well established technology (IBM System/360, 1964)
* Tilera have developed 64 core (TILE64, 2007), and then a 100 core processor (2009). Founder Dr. Anant Agarwal leads the MIT Angstron Project to develop a 1,000 core processor (2012).
</script></section>
<section data-markdown><script type="text/template">
### Part I: Memory Distribution
* In a  multiprocessor computer system memory can either be distributed or shared. Memory coherence is an issue is shared memory environments.
* HPC Clusters use memory distributed between compute nodes and shared within compute nodes.
* Operating systems like Plan 9 from Bell Labs creates a network function as a single collection of system resources.
* OpenMP uses shared memory parallelism; MPI uses distributed memory parallelism. The latter can cross compute nodes.
</script></section>
<section data-markdown><script type="text/template">
### Part I: Speedup and Locks
* The speedup of parallelism can be measured: Speedup (p) = Time (serial)/ Time (parallel). Ideal (linear) speedup is S(p) = p.
* Correctness requires requires synchronisation (locking). Synchronisation and atomic operations causes loss of performance, communication latency. 
</script></section>
<section data-markdown><script type="text/template">
### Part I: Deadlocks and Livelocks
* "When two trains approach each other at a crossing, both shall come to a full stop and neither shall start up again until the other has gone." (apocryphal Kansas railway statute)
* "When two people approach each other in a crowded corridor, both shall move out of the way of the other, and shall continue to move until they have an open path for progress" (Polite Persons in a Corridor Problem)
</script></section>
<section data-markdown><script type="text/template">
### Part I: Amdahl's Law 
* Because some of the task is in serial, there is a limit to the speedup based on the time that is required for the sequential task - no matter how many processors are thrown at the problem.
<img src="https://raw.githubusercontent.com/UoM-ResPlat-DevOps/SpartanParallel/master/Images/amdhal.png" />
</script></section>
<section data-markdown><script type="text/template">
### Part I: Gustafson-Barsis Law
* Gene Amdahl proposed his law in 1967; it wasn't until over twenty years later in 1988 that an alternative by John L. Gustafson and Edwin H. Barsis was offered. 
* Amadahl's Law assumed a computation problem of fixed data set size. Programmers tend to set the size of their computational problems according to the available equipment; therefore as faster and more parallel equipment becomes available, larger problems can be solved.
</script></section>
<section data-markdown><script type="text/template">
### Part II: Data Parallel Jobs
* Data parallel jobs are the simplest type of parallelism - and the most common.
* Single threaded jobs (such as MATLAB, R etc) can be launched across multiple datasets by using job arrays.
* Example job arrays in Slurm at: `/usr/local/common/array`
* Note that the index values and step size can be varied.
</script></section>
<section data-markdown><script type="text/template">
### Part II: Task Parallel Jobs
* Task parallel jobs require a communications systems whether it is through threads (OpenMP) or by message passing (OpenMPI).
* Thread-based parallelism requires that the tasks occur within the same computer node (shared memory). Message passing can distribute information between compute nodes (distributed memory).
* In Slurm scripts on Spartan MPI programmes will need to set the paths to the OpenMPI wrappers (`module avail OpenMPI`). Some simple examples are available at: `/usr/local/common/OpenMPI`
</script></section>
<section data-markdown><script type="text/template">
<img src="https://raw.githubusercontent.com/UoM-ResPlat-DevOps/SpartanParallel/master/Images/distmemory.png" />
</script></section>
    </div>

</div>

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>

    // Full list of configuration options available at:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: false,

        transition: 'convex', // none/fade/slide/convex/concave/zoom

        // Optional reveal.js plugins
        dependencies: [
            {
                src: 'reveal.js/lib/js/classList.js', condition: function () {
                return !document.body.classList;
            }
            },
            {
                src: 'reveal.js/plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            }
            },
            {
                src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function () {
                return !!document.querySelector('pre code');
            }, callback: function () {
                hljs.initHighlightingOnLoad();
            }
            },
            {src: 'reveal.js/plugin/zoom-js/zoom.js', async: true},
            {src: 'reveal.js/plugin/notes/notes.js', async: true}
        ]
    });

</script>

</body>
</html>
